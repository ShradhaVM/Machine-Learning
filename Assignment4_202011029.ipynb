{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4_202011029.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python38564bitc5a801491e894cea92f49402976df01d",
      "display_name": "Python 3.8.5 64-bit",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaAyRVaO4k9B"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split \n",
        "import scipy.stats\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn import metrics "
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRZRKT-I44kd"
      },
      "source": [
        "iris = load_iris() \n",
        "data_list = iris.data \n",
        "target_list = iris.target "
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xLqerUELe9c"
      },
      "source": [
        "# function for finding the gassian pdf\n",
        "def gauss_pdf(i, mean, variance) : \n",
        "  return (1/(np.sqrt(variance) * np.sqrt(2 * np.pi)) * np.exp( - (i - mean)**2 / (2 * variance)))\n",
        "\n",
        "# function for obtaining naive bayes classifier if we have 12 pdfs for each feature in each class\n",
        "def bayes_dec(test_set, result_list) : \n",
        "  \n",
        "  p1_f1 = gauss_pdf(i[0], f1_c1_mean, f1_c1_std**2)\n",
        "  p1_f2 = gauss_pdf(i[1], f2_c1_mean, f2_c1_std**2)\n",
        "  p1_f3 = gauss_pdf(i[2], f3_c1_mean, f3_c1_std**2)\n",
        "  p1_f4 = gauss_pdf(i[3], f4_c1_mean, f4_c1_std**2)\n",
        "\n",
        "  p2_f1 = gauss_pdf(i[0], f1_c2_mean, f1_c2_std**2)\n",
        "  p2_f2 = gauss_pdf(i[1], f2_c2_mean, f2_c2_std**2)\n",
        "  p2_f3 = gauss_pdf(i[2], f3_c2_mean, f3_c2_std**2)\n",
        "  p2_f4 = gauss_pdf(i[3], f4_c2_mean, f4_c2_std**2)\n",
        "\n",
        "  p3_f1 = gauss_pdf(i[0], f1_c3_mean, f1_c3_std**2)\n",
        "  p3_f2 = gauss_pdf(i[1], f2_c3_mean, f2_c3_std**2)\n",
        "  p3_f3 = gauss_pdf(i[2], f3_c3_mean, f3_c3_std**2)\n",
        "  p3_f4 = gauss_pdf(i[3], f4_c3_mean, f4_c3_std**2)\n",
        "\n",
        "  p1 = p1_f1*p1_f2*p1_f3*p1_f4\n",
        "  p2 = p2_f1*p2_f2*p2_f3*p2_f4\n",
        "  p3 = p3_f1*p3_f2*p3_f3*p3_f4\n",
        "\n",
        "  if max(p1, p2, p3) == p1:\n",
        "    result_list.append(0)\n",
        "  elif max(p1,p2,p3) == p2:\n",
        "    result_list.append(1)\n",
        "  else:\n",
        "    result_list.append(2)\n",
        "\n",
        "# function for gaussian naive bayes using sklearn\n",
        "def gaussian_nb(X_train, X_test, Y_train, Y_test, result_list) : \n",
        "  gnb = GaussianNB() \n",
        "  gnb.fit(X_train, Y_train) \n",
        "  y_pred = gnb.predict(X_test) \n",
        "  res.append(metrics.accuracy_score(Y_test, y_pred)*100)"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ExpSa2F48GS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9b860c-01fd-4b84-b4f3-33c4be2d6d28"
      },
      "source": [
        "print(\"Experiment with Naive Bayes Classification from scratch\")\n",
        "print(\"=======================================================\\n\")\n",
        "\n",
        "itr = 10\n",
        "accuracy1 = []\n",
        "accuracy2 = []\n",
        "\n",
        "for k in range(itr) : \n",
        "\n",
        "  X1_train, X1_test, Y1_train, Y1_test = train_test_split(data_list[0:50], target_list[0:50], test_size = 0.2)\n",
        "  X2_train, X2_test, Y2_train, Y2_test = train_test_split(data_list[50:100], target_list[50:100], test_size = 0.2)\n",
        "  X3_train, X3_test, Y3_train, Y3_test = train_test_split(data_list[100:150], target_list[100:150], test_size = 0.2)\n",
        "\n",
        "  # calculating mean across Columns of all three classes\n",
        "  column_mean1 = np.mean(X1_train, axis=0) \n",
        "  f1_c1_mean = round(column_mean1[0],2)   \n",
        "  f2_c1_mean = round(column_mean1[1],2)  \n",
        "  f3_c1_mean = round(column_mean1[2],2) \n",
        "  f4_c1_mean = round(column_mean1[3],2) \n",
        "\n",
        "  column_mean2 = np.mean(X2_train, axis=0) \n",
        "  f1_c2_mean = round(column_mean2[0],2)   \n",
        "  f2_c2_mean = round(column_mean2[1],2)  \n",
        "  f3_c2_mean = round(column_mean2[2],2) \n",
        "  f4_c2_mean = round(column_mean2[3],2) \n",
        "\n",
        "  column_mean3 = np.mean(X3_train, axis=0) \n",
        "  f1_c3_mean = round(column_mean3[0],2)   \n",
        "  f2_c3_mean = round(column_mean3[1],2)  \n",
        "  f3_c3_mean = round(column_mean3[2],2) \n",
        "  f4_c3_mean = round(column_mean3[3],2) \n",
        "\n",
        "  # Calculating standard deviation across Columns of all three classes\n",
        "  column_std1 = np.std(X1_train, axis=0) \n",
        "  f1_c1_std = round(column_std1[0],2)\n",
        "  f2_c1_std = round(column_std1[1],2)  \n",
        "  f3_c1_std = round(column_std1[2],2) \n",
        "  f4_c1_std = round(column_std1[3],2) \n",
        "\n",
        "  column_std2 = np.std(X2_train, axis=0) \n",
        "  f1_c2_std = round(column_std2[0],2)   \n",
        "  f2_c2_std = round(column_std2[1],2)  \n",
        "  f3_c2_std = round(column_std2[2],2) \n",
        "  f4_c2_std = round(column_std2[3],2)\n",
        "\n",
        "  column_std3 = np.std(X3_train, axis=0) \n",
        "  f1_c3_std = round(column_std3[0],2)   \n",
        "  f2_c3_std = round(column_std3[1],2)  \n",
        "  f3_c3_std = round(column_std3[2],2) \n",
        "  f4_c3_std = round(column_std3[3],2)\n",
        "\n",
        "  # initialising the result array for all three class train sets\n",
        "  res1 = []\n",
        "  res2 = []\n",
        "  res3 = []\n",
        "  acc = 0\n",
        "\n",
        "  # running naive bayes for each test class\n",
        "  for i in X1_test : \n",
        "    bayes_dec(X1_test, res1)\n",
        "  for i in X2_test : \n",
        "    bayes_dec(X2_test, res2)\n",
        "  for i in X3_test : \n",
        "    bayes_dec(X3_test, res3)\n",
        "\n",
        "  # comparing result with target set \n",
        "  for i in range(10) : \n",
        "    if res1[i] == Y1_test[i] : \n",
        "      acc += 1\n",
        "  for i in range(10) :\n",
        "    if res2[i] == Y2_test[i] : \n",
        "      acc += 1\n",
        "  for i in range(10) : \n",
        "    if res3[i] == Y3_test[i] :\n",
        "      acc += 1\n",
        "\n",
        "  accuracy1.append(acc/30*100)\n",
        "  print(\"Accuracy using own approach for iteration no.\", k+1, \"-->\",(round(acc/30*100,2)))\n",
        "\n",
        "  # performing gaussian naive bayes using sklearn on each class separately\n",
        "  res = []\n",
        "  gaussian_nb(X1_train, X1_test, Y1_train, Y1_test, res)\n",
        "  gaussian_nb(X2_train, X2_test, Y2_train, Y2_test, res)\n",
        "  gaussian_nb(X3_train, X3_test, Y3_train, Y3_test, res)\n",
        "\n",
        "  accuracy2.append(np.average(res))\n",
        "  print(\"Accuracy using Scikit-learn for iteration no.\", k+1, \"-->\", np.average(res), \"\\n\")\n",
        "\n",
        "print(\"================================================================\")\n",
        "print(\"Average Accuracy using own approach over\", itr, \"iterations -->\", round(np.average(accuracy1),2))\n",
        "print(\"Average Accuracy using Scikit-learn over\", itr, \"iterations -->\", round(np.average(accuracy2),2))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment with Naive Bayes Classification from scratch\n",
            "=======================================================\n",
            "\n",
            "Accuracy using own approach for iteration no. 1 --> 100.0\n",
            "Accuracy using Scikit-learn for iteration no. 1 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 2 --> 96.67\n",
            "Accuracy using Scikit-learn for iteration no. 2 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 3 --> 100.0\n",
            "Accuracy using Scikit-learn for iteration no. 3 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 4 --> 90.0\n",
            "Accuracy using Scikit-learn for iteration no. 4 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 5 --> 100.0\n",
            "Accuracy using Scikit-learn for iteration no. 5 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 6 --> 93.33\n",
            "Accuracy using Scikit-learn for iteration no. 6 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 7 --> 96.67\n",
            "Accuracy using Scikit-learn for iteration no. 7 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 8 --> 96.67\n",
            "Accuracy using Scikit-learn for iteration no. 8 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 9 --> 96.67\n",
            "Accuracy using Scikit-learn for iteration no. 9 --> 100.0 \n",
            "\n",
            "Accuracy using own approach for iteration no. 10 --> 100.0\n",
            "Accuracy using Scikit-learn for iteration no. 10 --> 100.0 \n",
            "\n",
            "================================================================\n",
            "Average Accuracy using own approach over 10 iterations --> 97.0\n",
            "Average Accuracy using Scikit-learn over 10 iterations --> 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}