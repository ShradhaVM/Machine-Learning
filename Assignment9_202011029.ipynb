{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRML_Assignment9_202011029.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz2iWhZIRLZd"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris \n",
        "from scipy.stats import multivariate_normal\n",
        "from scipy.stats import mode\n",
        "import random\n",
        "from sklearn.metrics.cluster import adjusted_rand_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABeUx2YfRMJf"
      },
      "source": [
        "iris = load_iris()\n",
        "data = iris.data\n",
        "target = iris.target"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxHS_KYDfIMu"
      },
      "source": [
        "# Performing Clustering using Gaussian Mixture Models \n",
        "*   in the iris dataset\n",
        "*   matching the resulted clusters with the original labels with the help of adjusted Rand score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpF0w9ssRPZ_"
      },
      "source": [
        "#Initialization\n",
        "k = 3\n",
        "max_itr = 5\n",
        "n, m = data.shape\n",
        "phi = np.zeros(k)\n",
        "weights = np.zeros(data.shape)\n",
        "\n",
        "\n",
        "# initializing phi and weights\n",
        "for i in range(k):\n",
        "  phi[i] = 1/k\n",
        "for i in range(n):\n",
        "  for j in range(m):\n",
        "    weights[i][j] = 1/k\n",
        "\n",
        "# initializing centroids\n",
        "initial_centroids = random.sample(range(0,149), k)\n",
        "# initializing mean and covariance matrix\n",
        "mu = [data[row_index,:] for row_index in initial_centroids]\n",
        "sigma = [np.cov(np.transpose(data)) for _ in range(k)]"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mCOAQnJSpLh"
      },
      "source": [
        "# Probability function for each class Ï•, by averaging over all examples in the training set\n",
        "def probability_predict(data):\n",
        "  likelihood = np.zeros((n, k))\n",
        "  for i in range(k):\n",
        "    gauss_dist = multivariate_normal(mean=mu[i], cov=sigma[i])\n",
        "    likelihood[:,i] = gauss_dist.pdf(data)\n",
        "\n",
        "  numerator = likelihood * phi\n",
        "  denominator = numerator.sum(axis=1)[:, np.newaxis]\n",
        "  weights = numerator / denominator\n",
        "  return weights\n",
        "\n",
        "# Returning index of maximum probability\n",
        "def predict(data):\n",
        "  return np.argmax(probability_predict(data), axis=1)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxdKGAl9alQ0"
      },
      "source": [
        "# Updating weights, phi,  mean and covariance matrix\n",
        "for i in range(max_itr):\n",
        "  weights = probability_predict(data)\n",
        "  phi = weights.mean(axis=0)\n",
        "\n",
        "  for j in range(k):\n",
        "    weight = weights[:, [j]]\n",
        "    total_weight = weight.sum()\n",
        "    mu[j] = (data * weight).sum(axis=0) / total_weight\n",
        "    sigma[j] = np.cov(np.transpose(data), aweights=(weight/total_weight).flatten())"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVGv39sRGnM7"
      },
      "source": [
        "labels = predict(data)"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbTT7zrFstMi",
        "outputId": "5caed94a-f79d-438a-ab3b-695668822c50"
      },
      "source": [
        "# Calculating adjusted rand score\n",
        "score = adjusted_rand_score(labels, target)\n",
        "print(\"Adjusted Rand score:\", score)"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adjusted Rand score: 0.5586216751698382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbbmrnfJtWy4",
        "outputId": "98583987-f8bf-43b3-c034-31a045b6c71a"
      },
      "source": [
        "# Finding row indices of target and predicted labels for jaccard similiarity later\n",
        "target_rows = [[0 for i in range(0)] for j in range(k)]\n",
        "for i in range(len(target)):\n",
        "  target_rows[target[i]].append(i)\n",
        "print(\"Row indices of the target labels -->\", target_rows)\n",
        "\n",
        "pred_rows = [[0 for i in range(0)] for j in range(k)]\n",
        "for i in range(len(labels)):\n",
        "  pred_rows[labels[i]].append(i)\n",
        "print(\"Row indices of predicted labels --->\", pred_rows)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row indices of the target labels --> [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]]\n",
            "Row indices of predicted labels ---> [[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 111, 113, 116, 117, 118, 119, 122, 124, 125, 127, 128, 129, 130, 131, 133, 134, 135, 137, 138, 142, 146, 149], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 60, 79, 93], [100, 109, 110, 112, 114, 115, 120, 121, 123, 126, 132, 136, 139, 140, 141, 143, 144, 145, 147, 148]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiyatDgJuL6I"
      },
      "source": [
        "# Jaccard similiarity for accuracy\n",
        "gmm_jaccard = [0,0,0]\n",
        "\n",
        "for i in range(len(pred_rows)):\n",
        "  sim = [0, 0, 0]\n",
        "  # finds the no of similar elements and updates the sim matrix accordingly\n",
        "  for j in range(len(pred_rows[i])):\n",
        "    for l in range(3):\n",
        "      if pred_rows[i][j] in target_rows[l]:\n",
        "        sim[l] += 1\n",
        "  # for finding out the most similar set between target and predicted labels\n",
        "  max_sim = sim.index(np.amax(sim))\n",
        "  u_list = list(set(pred_rows[i]) | set(target_rows[max_sim]))\n",
        "  i_list = list(set(pred_rows[i]) & set(target_rows[max_sim]))\n",
        "\n",
        "  gmm_jaccard[i] = len(i_list)/len(u_list)\n",
        "\n",
        "accuracy = (gmm_jaccard[0]*len(pred_rows[0]))/len(data) + (gmm_jaccard[1]*len(pred_rows[1]))/len(data) + (gmm_jaccard[2]*len(pred_rows[2]))/len(data)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQSZ_KakvAjl",
        "outputId": "30ce69ed-0a91-496b-f958-5c424487c833"
      },
      "source": [
        "print(\"Accuracy of Gaussian Mixture Model  -->\",round(accuracy*100,2))\n",
        "print(\"Adjusted Rand score using sk-learn -->\", round(score,2))"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Gaussian Mixture Model  --> 68.83\n",
            "Adjusted Rand score using sk-learn --> 0.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCIH82SwfbAU"
      },
      "source": [
        "# Performing in-built logistic regression on training data and classify test data.\n",
        "*   using IRIS data to generate training data and test data\n",
        "*   choosing 40 random data points from each class for training data\n",
        "*   using the remaining 10 data points from each class as test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUQsvschhfaW",
        "outputId": "9f3bf0d0-90a5-4cb8-b4bd-7726fc5b6830"
      },
      "source": [
        "warnings.filterwarnings('ignore' )\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size = 0.2)\n",
        "\n",
        "lr_classifier = LogisticRegression(random_state=0).fit(X_train, Y_train)\n",
        "lr_classifier.predict(X_test)\n",
        "lr_accuracy = clf.score(X_train, Y_train)\n",
        "\n",
        "print(\"Accuracy of Logictic Regression using sk-learn  -->\",round(lr_accuracy*100,2))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Logictic Regression using sk-learn  --> 97.5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}